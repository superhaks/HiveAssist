# ------ Camera Operations ------
#img_file_buffer = camera_in.camera_input("")

#getting Processed features into variables
#m_face, m_left_eye, m_right_eye, m_dominant_emotion = image_processing(img_file_buffer)



# def display_eye_tracking_info():
#     camera_in.write(f"Co-ordinates for Left eye: {m_left_eye}, Right eye: {m_right_eye}")

# def display_face_detection_info():
#     camera_in.write(f"Co-ordinates of Face: {m_face}")

# def display_emotion_detection_info():
#     camera_in.write(f"Dominant Emotion : {m_dominant_emotion}")

# # Display selected features
# for selected_option in selected_options:
#     if selected_option == "Eye Tracking":
#         display_eye_tracking_info()
#     elif selected_option == "Face Detection":
#         display_face_detection_info()
#     elif selected_option == "Emotion Detection":
#         display_emotion_detection_info()




#--- Dict check ---- 
# -----
# camera_in.write(faces)
# camera_in.write("---")
# camera_in.write(objs)


#DeepFace.stream("pages/FaceData","VGG-Face","opencv","euclidean_l2")